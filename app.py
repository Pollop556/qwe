import torch
from unsloth import FastLanguageModel
from datasets import Dataset
import pandas as pd
from trl import SFTTrainer
from transformers import TrainingArguments

def train():
    # 1. üöÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Qwen 2.5 3B Instruct ‚Äî –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –≤ —ç—Ç–æ–º –∫–ª–∞—Å—Å–µ
    model_name = "Qwen/Qwen2.5-3B-Instruct" 
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. 2048 —Ç–æ–∫–µ–Ω–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–¥–Ω–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–æ–±—ã—á–Ω–æ ~500-1000 —Å–ª–æ–≤).
    # –ï—Å–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 4096, –Ω–æ —ç—Ç–æ –∑–∞–π–º–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏.
    max_seq_length = 2048 
    
    dtype = None # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (float16 –¥–ª—è T4)
    load_in_4bit = True # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ True –¥–ª—è T4 (16GB), –∏–Ω–∞—á–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–ª–µ–∑–µ—Ç –∏–ª–∏ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ–π

    print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}...")
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name = model_name,
        max_seq_length = max_seq_length,
        dtype = dtype,
        load_in_4bit = load_in_4bit,
    )

    # 2. ‚ö° –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ Qwen)
    # Qwen –∏–º–µ–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–æ–¥—É–ª–∏ (q,k,v,o,gate,up,down), –º—ã –æ–±—É—á–∞–µ–º –∏—Ö –≤—Å–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    model = FastLanguageModel.get_peft_model(
        model,
        r = 16, # –†–∞–Ω–≥ –∞–¥–∞–ø—Ç–µ—Ä–∞. 16 ‚Äî –∑–æ–ª–æ—Ç–∞—è —Å–µ—Ä–µ–¥–∏–Ω–∞ (–º–æ–∂–Ω–æ 32 –∏–ª–∏ 64, –Ω–æ 16 –±—ã—Å—Ç—Ä–µ–µ –∏ –ø–∞–º—è—Ç–∏ –º–µ–Ω—å—à–µ)
        target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                          "gate_proj", "up_proj", "down_proj",],
        lora_alpha = 16, # Alpha = r (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞)
        lora_dropout = 0, # 0 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        bias = "none",    # "none" –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –ø–∞–º—è—Ç–∏
        use_gradient_checkpointing = "unsloth", # –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM
        random_state = 3407,
        use_rslora = False,
        loftq_config = None,
    )

    # 3. üìÇ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    df = pd.read_csv('shuffled_dataset.csv')
    dataset = Dataset.from_pandas(df)

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ Qwen Chat Template
    def formatting_prompts_func(examples):
        texts = []
        for input_text, output_text in zip(examples["input"], examples["target"]):
            messages = [
                # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ‚Äî –∑–∞–¥–∞–µ—Ç —Ä–æ–ª—å –∏ —Å—Ç–∏–ª—å.
                {"role": "system", "content": "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥-–∫—É—Ä–∞—Ç–æ—Ä. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ, –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –∏ –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏ –≥—Ä–∞–º–æ—Ç–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤. –°—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, —Å–¥–µ—Ä–∂–∞–Ω–Ω—ã–π, –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π."},
                
                # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                {"role": "user", "content": f"–°–æ—Å—Ç–∞–≤—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É –Ω–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –¥–∞–Ω–Ω—ã–º: {input_text}"},
                
                # –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (—Ç–æ, —á–µ–º—É —É—á–∏–º –º–æ–¥–µ–ª—å)
                {"role": "assistant", "content": output_text}
            ]
            
            # apply_chat_template —Å–∞–º –¥–æ–±–∞–≤–∏—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã <|im_start|> –∏ <|im_end|> –¥–ª—è Qwen
            text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
            texts.append(text)
        return { "text" : texts, }

    dataset = dataset.map(formatting_prompts_func, batched = True,)

    # 4. üî• –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (Training Arguments)
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ dataset ~500 –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –º–æ–¥–µ–ª—å 3B
    print("üî• –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    trainer = SFTTrainer(
        model = model,
        tokenizer = tokenizer,
        train_dataset = dataset,
        dataset_text_field = "text",
        max_seq_length = max_seq_length,
        dataset_num_proc = 2,
        packing = False, 
        args = TrainingArguments(
            per_device_train_batch_size = 2,   # –ë–∞—Ç—á 2 –Ω–∞ –∫–∞—Ä—Ç—É (–≤–ª–µ–∑–∞–µ—Ç –≤ 16GB)
            gradient_accumulation_steps = 4,   # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –±–∞—Ç—á = 2 * 4 = 8
            warmup_steps = 10,                 # –†–∞–∑–æ–≥—Ä–µ–≤ (—á—É—Ç—å –±–æ–ª—å—à–µ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏)
            num_train_epochs = 3,              # 3 —ç–ø–æ—Ö–∏ –æ–±—ã—á–Ω–æ –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è ~500 –ø—Ä–∏–º–µ—Ä–æ–≤. 
                                               # –ï—Å–ª–∏ 1 —ç–ø–æ—Ö–∞, –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—É—á–∏—Ç—Å—è. –ï—Å–ª–∏ 10 ‚Äî –ø–µ—Ä–µ—É—á–∏—Ç—Å—è (–∑–∞–∑—É–±—Ä–∏—Ç).
            learning_rate = 2e-4,              # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π LR –¥–ª—è QLoRA
            fp16 = not torch.cuda.is_bf16_supported(),
            bf16 = torch.cuda.is_bf16_supported(),
            logging_steps = 1,
            optim = "adamw_8bit",              # 8-–±–∏—Ç–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
            weight_decay = 0.01,
            lr_scheduler_type = "linear",
            seed = 3407,
            output_dir = "outputs",
            report_to = "none", # –û—Ç–∫–ª—é—á–∞–µ–º wandb —á—Ç–æ–±—ã –Ω–µ –ª–æ–≥–∏–Ω–∏—Ç—å—Å—è –ª–∏—à–Ω–∏–π —Ä–∞–∑
        ),
    )

    trainer.train()

    # 5. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–¥–∞–ø—Ç–µ—Ä—ã
    model.save_pretrained("lora_model") 
    tokenizer.save_pretrained("lora_model")

    # –≠–∫—Å–ø–æ—Ä—Ç –≤ GGUF –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω–∞ –Ω–æ—É—Ç–±—É–∫–µ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º q4_k_m ‚Äî –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è 3B –º–æ–¥–µ–ª–µ–π
    print("üì¶ –≠–∫—Å–ø–æ—Ä—Ç –≤ GGUF (q4_k_m)...")
    try:
        model.save_pretrained_gguf("model_gguf", tokenizer, quantization_method = "q4_k_m")
        print("üéâ –£–°–ü–ï–•! –§–∞–π–ª GGUF —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–ø–∫—É 'model_gguf'. –°–∫–∞—á–∞–π –µ–≥–æ!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ GGUF: {e}")

if __name__ == "__main__":
    train()
